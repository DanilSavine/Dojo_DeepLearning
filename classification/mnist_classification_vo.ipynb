{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "CQw72yK8qkxU"
   },
   "source": [
    "# Classifying digits using a fully connected neural network\n",
    "\n",
    "In this practical exercice a fully connected neural network (also called multi-layer perceptron) is built using keras. It is then trained to classify image digits from the MNIST database. The MNIST database is a set of 28x28 grey-level, centered images of digits. \n",
    "\n",
    "Some baseline results:\n",
    "\n",
    "| Method                                                                      | Test error (%) |\n",
    "|-----------------------------------------------------------------------------|---------------:|\n",
    "| Linear classifier (LeCun et al. 1998)                                       |           12.0 |\n",
    "| K-nearest-neighbors, Euclidean (L2) (LeCun et al. 1998)                     |            5.0 |\n",
    "| 3-layer NN, 500-300, softmax, cross entropy, weight decay (Hinton, 2005)    |            1.5 |\n",
    "| Convolutional net LeNet-4 (LeCun et al. 1998)                               |            1.1 |\n",
    "| Virtual SVM deg-9 poly [data augmentation] (LeCun et al. 1998)              |            0.8 |\n",
    "| 6-layer NN with [data augmentation] (Ciresan et al. 2010)                   |           0.35 |\n",
    "| Deep conv. net, 7 layers [data augmentation] (Ciresan et al. IJCAI 2011)    |           0.35 |\n",
    "\n",
    "More results are available from: http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "Try to improve on some of these results, at least on those that do not use data augmentation or convolutional neural networks.\n",
    "\n",
    "Teaching assistant: romain.vo@mines-paristech.fr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "HJLLB22SJabj"
   },
   "source": [
    "## Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YU9Ro5_eqkxZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.keras.datasets import mnist as db\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Magic used by the notebook to show figures inline\n",
    "%matplotlib inline\n",
    "# matplotlib default values\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# auto-reloading packages\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset is a widely used baseline for classifcation, and deep learning methods specifically, and as such is directly available through the keras API. The data is split in training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "(x, y), (x_test_ori, y_test_ori) = db.load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First look\n",
    "\n",
    "Have a look at the data. You can run the next cell several times to have a look at different instances of the same class. \n",
    "\n",
    "**#i** here denotes the number of samples which belongs to the class **i**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x576 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=5, figsize=(16,8))\n",
    "ax = ax.reshape(-1)\n",
    "\n",
    "for i in range(10):\n",
    "    class_mask = np.nonzero(y == i)[0]\n",
    "    index = np.random.choice(class_mask)\n",
    "    ax[i].imshow(x[index])\n",
    "    ax[i].axis('off')\n",
    "    ax[i].set_title(f\"Index: {index}, Class: {y[index]} \\n #{y[index]} = {class_mask.shape[0]}\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "GkMZFMI58vHi"
   },
   "source": [
    "### Data preparation\n",
    "\n",
    "<u>Splitting :</u> The training subset of the MNIST database contains 60000 images. We will split this set into an effective training set (90%) and a validation set (10%). This will allow us to improve our model without looking at the test set. As a rule of thumb the test should be evaluated very very few times, only when you think you have reach the end of your improvement procedure.\n",
    "\n",
    "<u>Normalization :</u> We need to normalize the data before feeding it to the neural network, this is done simply by dividing the pixel values by 255.\n",
    "\n",
    "<u>Formatting the input:</u> For the moment, the training data (the images) are stored in 2D arrays. Because we are using *Fully connected layers* (**FCL**), also called *Multi-Layer Perceptron* (**MLP**), we only need 1D vector as input. Thus we flatten the 2D arrays beforehand. \n",
    "- `x[idx].shape = (28,28)`  $\\rightarrow$  `x[idx].shape = (784)`\n",
    "\n",
    "<u>Formatting the output:</u> For the moment, the target is simply stored by assigning to each index of the `y` array, the corresponding digit value. Here our future **MLP** will compute an `output` tensor of 10 \"probabilities\" (between 0 and 1) for each image. Thus for an image of the digit `8` we would like `output[7]` to be equal to 1. To learn such a network we also need to format the `y` array into a relevant encoding. So we apply a *one-hot encoding* to each value stored in `y` :\n",
    "- `y[idx] = 8`  $\\rightarrow$  `y[idx] = [0, 0, 0, 0, 0, 0, 0, 1, 0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X8RpHz6yqkxs",
    "outputId": "50a0df47-8531-4cca-f3ab-8054aae57c2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54000, 784) x train samples\n",
      "(6000, 784) x val samples\n",
      "(10000, 784) x test samples\n",
      "(54000, 10) y train samples\n",
      "(6000, 10) y val samples\n",
      "(10000,) y test samples\n"
     ]
    }
   ],
   "source": [
    "# Data management\n",
    "val_nb = 6000  # number of validation samples\n",
    "nb_samples = x.shape[0]\n",
    "\n",
    "if val_nb > nb_samples:\n",
    "    raise ValueError(\"You need some samples to train your network!\")\n",
    "\n",
    "img_width, img_height = x.shape[1], x.shape[2]\n",
    "\n",
    "num_of_pixels = img_width * img_height\n",
    "\n",
    "# As we are using only fully connected layers, we need a vector as input\n",
    "x = x.reshape(nb_samples, num_of_pixels)\n",
    "x_test = x_test_ori.reshape(x_test_ori.shape[0], num_of_pixels)\n",
    "\n",
    "# Normalization\n",
    "x = x.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x /= 255\n",
    "x_test /= 255\n",
    "\n",
    "x_val = x[:val_nb, ]\n",
    "x_train = x[val_nb:, ]\n",
    "y_val = y[:val_nb]\n",
    "y_train = y[val_nb:]\n",
    "\n",
    "# one-hot encoding of classes\n",
    "num_classes = max(y) + 1\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_val = to_categorical(y_val, num_classes)\n",
    "y_test = to_categorical(y_test_ori, num_classes)\n",
    "\n",
    "\n",
    "print(x_train.shape, 'x train samples')\n",
    "print(x_val.shape, 'x val samples')\n",
    "print(x_test.shape, 'x test samples')\n",
    "print(y_train.shape, 'y train samples')\n",
    "print(y_val.shape, 'y val samples')\n",
    "print(y_test_ori.shape, 'y test samples')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "MwtzNojFqkxy"
   },
   "source": [
    "## First model\n",
    "\n",
    "We will begin with a network containing a single layer. We use a `softmax` activation for our last and single layer in order to normalize the `output` tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PcuVHd7xqkxz",
    "outputId": "ac5df66d-e6fd-46c8-c4dc-c9e49b029c14"
   },
   "outputs": [],
   "source": [
    "# let define a first simple model without any hidden layers\n",
    "model = Sequential()\n",
    "model.add(Dense(num_classes, activation='softmax', input_shape=(x_train.shape[1],)))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "VzQxdV8pqkx7"
   },
   "source": [
    "### Training\n",
    "\n",
    "The following section takes care of training.\n",
    "\n",
    "Firstly, the model has to be 'compiled'. This operations lets the user to choose the loss, the optimizer and the metrics, then configures the model for training. \n",
    "\n",
    "<u>Loss :</u> To train our model we choose a *categorical cross-entropy*, with $N$ the number of samples and $C$ the number of classes:\n",
    "- $L(y, \\hat{y}) = \\frac{1}{N} \\sum_{i=0}^N \\left( - \\sum_{c=1}^C y_{i,c} \\log(\\hat{y}_{i,c}) \\right)$  \n",
    "\n",
    "Implement a categorical cross-entropy using only `K.log`, `K.sum` , `K.mean` \n",
    "\n",
    "To check that your implement of `categorical_crossentropy` is correct, you should approximately have the same results when setting `loss='categorical_crossentropy'`, which uses the built-in implementation of keras.\n",
    "\n",
    "<u>Optimization :</u> Secondly, the 'fit' method runs the optimization. Training and validation data are specified here, as well as batch size and the number of epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ya91UWco4L-3"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "def categorical_crossentropy(target, prediction):\n",
    "    \"\"\" \n",
    "    target : array of shape [batch_size, num_classes]\n",
    "    prediction : array of shape [batch_size, num_classes]\n",
    "    \"\"\"\n",
    "\n",
    "    ### TO BE IMPLEMENTED ###\n",
    "  \n",
    "    ######################### \n",
    "    pass\n",
    "\n",
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=SGD(learning_rate=learning_rate),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer=SGD(learning_rate=learning_rate),\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "l989dszm4s81"
   },
   "source": [
    "Note that you can run the cell below several times. Training will restart from the point it stopped in the previous run. However variable *output* will only contain the history of the last run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 20\n",
    "output = model.fit(x_train, y_train,\n",
    "                   batch_size=batch_size,\n",
    "                   epochs=epochs,\n",
    "                   validation_data=(x_val, y_val))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "8O7Gu80gezI9"
   },
   "source": [
    "### Is training satisfactory?\n",
    "\n",
    "Looking at the evolution of training and validation accuracies, one can evaluate the quality of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "aQVPe8UMrtNH",
    "outputId": "4ca031ab-eb9f-4fde-9f02-bda4818566bb"
   },
   "outputs": [],
   "source": [
    "plt.plot(output.epoch, output.history['loss'], label='train')\n",
    "plt.plot(output.epoch, output.history['val_loss'], label='val')\n",
    "plt.title('Training and validation performance')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "LSVAWdNc6RYk"
   },
   "source": [
    "### Questions\n",
    "\n",
    "\n",
    "\n",
    "*   Do you think learning could be improved? Why?\n",
    "\n",
    "**Answer**: ...\n",
    "\n",
    "*   Is there overfitting? Why?\n",
    "\n",
    "**Answer**: ...\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "97QqiLS2qkyC"
   },
   "source": [
    "### Analysis of the weights\n",
    "\n",
    "With this simple model it is possible to have an intuition of what the neural network has learned looking at\n",
    "the matrix of the weights $W$. \n",
    "In fact $W\\in\\mathbb{R}^{784\\times 10}$, so for each class $i$ we can plot the weights corresponding to this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "VhGcciPwqkyE",
    "outputId": "621e2010-5f16-48a5-b284-34bd1cfd8f3f"
   },
   "outputs": [],
   "source": [
    "# plotting the weights \n",
    "W, b = model.layers[0].get_weights()\n",
    "vmin = W.min()\n",
    "vmax = W.max()\n",
    "f, ax = plt.subplots(2, 5, figsize=(16,6))\n",
    "for plt_row in range(2):\n",
    "    for plt_col in range(5):\n",
    "        ax[plt_row][plt_col].imshow(W[:,plt_row*5 + plt_col].reshape(img_width,img_height), vmin=vmin, vmax=vmax, cmap=plt.cm.bwr)\n",
    "        ax[plt_row][plt_col].axis('off')\n",
    "        ax[plt_row][plt_col].set_title(\"Weights for the class {}\".format(plt_row*5 + plt_col))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "nkdMfRLPqkyM"
   },
   "source": [
    "## Improving performance by adding extra layers\n",
    "\n",
    "In order to improve the performances of our prediction it is possible to add hidden layers between the input layer and the output layer.\n",
    "\n",
    "Note that here we are restricted to dense layers. Do not use (yet) other types of layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bi3_oPtnqkyO",
    "outputId": "0af0b263-be5b-4953-a903-8471ae233561"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(x_train.shape[1],)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax', name=\"last\"))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "64qVmdPAqkyT"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=learning_rate),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yFwW-zSF7Ryi",
    "outputId": "fb56f9eb-7036-476d-f841-5094abc6a9ca"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 40\n",
    "output = model.fit(x_train, y_train,\n",
    "                   batch_size=batch_size,\n",
    "                   epochs=epochs,\n",
    "                   validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "JU_eMV9rqkyX"
   },
   "source": [
    "### Analysis of the results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "K0CKtpx_qkyZ",
    "outputId": "e88062a0-1202-44a2-abd4-77b42c1c8d97"
   },
   "outputs": [],
   "source": [
    "plt.plot(output.epoch, output.history['loss'], label='train')\n",
    "plt.plot(output.epoch, output.history['val_loss'], label='val')\n",
    "plt.title('Training and validation performance')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "# plt.ylim(0.2, 0.8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "mrggUv3Uf8fM"
   },
   "source": [
    "Is there overfitting? How can it be reduced?\n",
    "\n",
    "**Answer**: ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ojS_0h3LlWUZ"
   },
   "source": [
    "### Qualitative error analysis\n",
    "\n",
    "Let us have a look at some images that have been incorrectly classified. \n",
    "\n",
    "<u>Inference </u>: We call the `predict` method on our model and feed the `x_test` array to obtain the probabilities for each test sample. The `y_predict_proba` is a *one-hot encoded* array so we compute the index of the maximum predicted probability to extract the label of the predicted digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_proba = model.predict(x_test)\n",
    "y_predict = np.argmax(y_predict_proba, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the following cell several times to inspect different errors, or manually change the `index` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "78GfuYj9qkyf",
    "outputId": "3de69470-c6db-4b38-fdd1-6a3360e3578c"
   },
   "outputs": [],
   "source": [
    "err_mask = y_test_ori != y_predict\n",
    "ok_mask = y_test_ori == y_predict\n",
    "\n",
    "x_test_errors = x_test_ori[err_mask]\n",
    "y_test_errors = y_test_ori[err_mask]\n",
    "y_predict_errors = y_predict[err_mask]\n",
    "y_predict_proba_errors = y_predict_proba[err_mask]\n",
    "y_predict_proba_ok = y_predict_proba[ok_mask]\n",
    "\n",
    "index = np.random.choice(range(y_test_errors.shape[0]))\n",
    "print(f\"Correct label is: { y_test_errors[index]}\")\n",
    "print(f\"Predicted label is: {y_predict_errors[index]} with a \\\"probability\\\" of {y_predict_proba_errors[index, y_predict_errors[index]]:.2%}\")\n",
    "print(f\"Label {y_test_errors[index]} was predicted with a \\\"probability\\\" of {y_predict_proba_errors[index, y_test_errors[index]]:.2%}\", end='\\n\\n')\n",
    "print(f\"Probabilities: {y_predict_proba_errors[index]}\")\n",
    "plt.imshow(x_test_errors[index], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the histogram of the probabilities of the predicted classes, given that the predictions are correct or incorrect. This should give us some intuitions on how the network \"behaves\" during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p.max() keeps the highest probability among the 10 outputs.\n",
    "\n",
    "max_predictions_correct = np.max(y_predict_proba[ok_mask], 1)\n",
    "max_predictions_incorrect = np.max(y_predict_proba[err_mask], 1)\n",
    "\n",
    "# np.random.shuffle shuffles the values of the array\n",
    "np.random.shuffle(max_predictions_correct)\n",
    "np.random.shuffle(max_predictions_incorrect)\n",
    "\n",
    "y_predict_proba_errors.shape\n",
    "\n",
    "histo_bins = 20\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.hist(max_predictions_correct[0:100], density=False, \n",
    "         bins=histo_bins, \n",
    "         color=\"blue\", \n",
    "         alpha=0.4, \n",
    "         label='Correct predictions')\n",
    "ax.hist(max_predictions_incorrect[0:100],density=False, \n",
    "         bins=histo_bins, \n",
    "         color=\"orange\", \n",
    "         alpha=0.4, \n",
    "         label='Incorrect predictions')\n",
    "\n",
    "ax.set_title('Max probability histograms')\n",
    "ax.set_xlabel(\"Max probability\")\n",
    "ax.legend()\n",
    "\n",
    "sns.reset_defaults()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the network 'confident' when making errors?\n",
    "\n",
    "**Answer**: ...\n",
    "\n",
    "What do you think about these errors?\n",
    "\n",
    "**Answer**: ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantitative error analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can measure the uncertainty of our model by measuring the entropy of its predictions. In [information theory](https://en.wikipedia.org/wiki/Entropy_(information_theory)) the entropy of a random variable is given by $H(X) = - \\sum_{x \\in \\mathcal{X}} p(x) \\log\\left(p(x)\\right)$. In our case we can compute the entropy of a prediction using:\n",
    "- $H(\\hat{y}) = - \\sum_{c=1}^C \\hat{y}_{c} \\log(\\hat{y}_{c})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(predictions):\n",
    "    return - np.sum(predictions * np.log(predictions), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will plot the smoothed histogram (Kernel Density Estimation) of our predictions' entropy, given that the predictions are correct or incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "entropies = entropy(y_predict_proba)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.kdeplot(entropies[ok_mask], label='Correct predictions', ax=ax, fill=True)\n",
    "sns.kdeplot(entropies[err_mask], label='Incorrect predictions',ax=ax, fill=True)\n",
    "ax.set_xlim(0, 1.5)\n",
    "ax.set_xlabel('Entropy')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "sns.reset_defaults()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this plot what can you say about our model in terms of uncertainty ? Why ?\n",
    "\n",
    "**Answer**: ...\n",
    "\n",
    "Very quickly, What kind of prediction would maximize the entropy ? \n",
    "\n",
    "**Answer**: y = [?, ?, ?, ?, ?, ?, ?, ?, ?, ?]\n",
    "\n",
    "Based on the analysis of the entropy, design a procedure to estimate beforehand if a prediction will be wrong or not. What are the limits of your procedure ?\n",
    "\n",
    "You could use the following objects: `entropies, err_mask, ok_mask`\n",
    "\n",
    "**Answer**: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "######### Your code comes here #########\n",
    "########################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "CxWL0WV7cNfH"
   },
   "source": [
    "### Analysing the last layer\n",
    "\n",
    "Each neuron $i$ in the last layer of the network corresponds to one class. Its weights $W_i$ can be interpreted as the parameters of a hyperplane $H_i$ of $R^d$, where $d$ is the number of neurons of the previous layer.\n",
    "\n",
    "If two classes are correctly separated by the network, one can expect that the two corresponding hyperplanes are orthogonal. This can be evaluated by calculating the cosine between their normal vectors. This measure is called.... cosine similarity.\n",
    "\n",
    "Note that as $d$ increases, the expected value of the cosine of two random normal vectors of $R^d$ converges towards zero. Put otherwise: in high dimension, two random vectors tend to be orthogonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "ppayuQ6aHFbY",
    "outputId": "84779181-be2e-4f55-c69c-e774e28da9d5"
   },
   "outputs": [],
   "source": [
    "weights, bias = model.get_layer(\"last\").get_weights()\n",
    "print(\"Shape of the weights array:\", weights.shape)\n",
    "norms = []\n",
    "for neuron in range(weights.shape[1]):\n",
    "    norms += [np.linalg.norm(weights[:,neuron])]\n",
    "weights /= norms\n",
    "\n",
    "cos = np.matmul(weights.transpose(), weights)\n",
    "\n",
    "plt.imshow(cos)\n",
    "plt.set_cmap('Spectral')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cos)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "N4s25LwCgvMD"
   },
   "source": [
    "Which classes seem to be the most correlated? Would you have expected this?\n",
    "\n",
    "**Answer**: ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKRQ9qUtprcT"
   },
   "source": [
    "### Improving your network\n",
    "\n",
    "Try to improve the performance of your network: try different numbers of layers (do not use convolutional layers yet), as well as the number of neurons per layer.\n",
    "\n",
    "What is your best validation accuracy?\n",
    "\n",
    "**Answer**: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "### TO BE IMPLEMENTED ###\n",
    "\n",
    "#########################\n",
    "\n",
    "model.summary()\n",
    "\n",
    "learning_rate = 0.01\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=learning_rate),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 40\n",
    "output = model.fit(x_train, y_train,\n",
    "                   batch_size=batch_size,\n",
    "                   epochs=epochs,\n",
    "                   validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zWRkHtFkqkyj"
   },
   "source": [
    "### Testing\n",
    "\n",
    "Testing is the last stage of the learning process. Good practice recommends to do it only once, when you have completely finished with the optimization of the network parameters and hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LT0OkKrsqkyk",
    "outputId": "e06f2235-a0c3-40a9-8690-f554a40068dc"
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss: %.3f' % score[0])\n",
    "print('Test accuracy: %.3f' % score[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Ak0ABv3hoskM"
   },
   "source": [
    "### Confusion matrix\n",
    "\n",
    "Each value $C_{i,j}$ of the confusion matrix $C$ gives the number of elements known to belong to class $i$ that have been classified in class $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iVimIQ0WAHHv",
    "outputId": "ceac97d1-f041-4b3a-fd3c-2351ae471340"
   },
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict(x_test)\n",
    "y_pred = y_pred_proba.argmax(axis=-1)\n",
    "\n",
    "confusion_matrix(y_test_ori, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "fzEIC4_0jHrG"
   },
   "source": [
    "Which pair of classes causes the most confusion? Is it coherent with the analysis of the cosine similarity between neurons of the last layer? Why?\n",
    "\n",
    "**Answer**: ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Convolutional Layers\n",
    "\n",
    "In order experiment with convolutional networks and see their benefits, we can now use convolutional layers.\n",
    "\n",
    "<u>Formatting input: </u>: since we are going to use convolutional layers we need image data. We can map images back to their original domain in a 28 x 28 grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape([-1,28,28,1])\n",
    "x_val = x_val.reshape([-1,28,28,1])\n",
    "x_test = x_test.reshape([-1,28,28,1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will implement our first convolutional neural network. Using keras `Sequential` API, build a CNN with the following sequential architecture:\n",
    "\n",
    "        - Conv2D: 16 filters and a kernel of size (5x5), ReLU activation\n",
    "        - MaxPooling2D\n",
    "        - Conv2D: 32 filters and a kernel of size (3x3), ReLU activation\n",
    "        - MaxPooling2D\n",
    "        - Conv2D: 32 filters and a kernel of size (3x3), ReLU activation\n",
    "        - MLP: 128 neurons, ReLU activation\n",
    "        - MLP: num_classes neurons\n",
    "        - Softmax activation\n",
    "\n",
    "Dont forget, we are now working with images but the MLP layers only takes 1D vector as input.\n",
    "\n",
    "Use `help(Conv2D)`, etc.. directly in a cell to access the layers API or directly check on [keras](https://keras.io/api/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "### TO BE IMPLEMENTED ###\n",
    "\n",
    "# model.add(Conv2D(...))\n",
    "# model.add(MaxPool2D())\n",
    "\n",
    "# ...\n",
    "# ...\n",
    "\n",
    "# model.add(Dense(num_classes, .....))\n",
    "\n",
    "######################### \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "64qVmdPAqkyT"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(learning_rate=learning_rate),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yFwW-zSF7Ryi",
    "outputId": "fb56f9eb-7036-476d-f841-5094abc6a9ca"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 40\n",
    "output = model.fit(x_train, y_train,\n",
    "                   batch_size=batch_size,\n",
    "                   epochs=epochs,\n",
    "                   validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "K0CKtpx_qkyZ",
    "outputId": "e88062a0-1202-44a2-abd4-77b42c1c8d97"
   },
   "outputs": [],
   "source": [
    "plt.plot(output.epoch, output.history['loss'], label='train')\n",
    "plt.plot(output.epoch, output.history['val_loss'], label='val')\n",
    "plt.title('Training and validation performance')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "# plt.ylim(0.2, 0.8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it overfitting? What can you say about it when you compare with the denser architecture?\n",
    "What else can you do to reduce it?\n",
    "\n",
    "**Answer:** ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the Feature Maps\n",
    "\n",
    "We can try to understand what is happening in the network by looking at its feature maps. Since they are defined on a grid, we can vizualize them as images.\n",
    "\n",
    "Here we vizualize the feature maps of the first layer for some images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = x_test[np.random.randint(0, x_test.shape[0]), :, :, :]\n",
    "im = im[np.newaxis, ...]\n",
    "fmaps = model.layers[0](im)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(16):\n",
    "    plt.subplot(4,4,i+1)\n",
    "    plt.imshow(fmaps[0,:,:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = x_test[np.random.randint(0, x_test.shape[0]), :, :, :]\n",
    "im = im[np.newaxis, ...]\n",
    "fmaps = model.layers[0](im)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(16):\n",
    "    plt.subplot(4,4,i+1)\n",
    "    plt.imshow(fmaps[0,:,:,i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you identify if the convolutional layer detects meaningful features?(for example edges and corners)\n",
    "\n",
    "**Answer:** ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKRQ9qUtprcT"
   },
   "source": [
    "# Improving your network\n",
    "\n",
    "As before, try to improve your network by changing the number of layers of each type and the number of feature maps, neurons or kernel size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "### TO BE IMPLEMENTED ###\n",
    "\n",
    "######################### \n",
    "\n",
    "model.summary()\n",
    "\n",
    "learning_rate = 0.01\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(learning_rate=learning_rate),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 40\n",
    "output = model.fit(x_train, y_train,\n",
    "                   batch_size=batch_size,\n",
    "                   epochs=epochs,\n",
    "                   validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "What is your best validation accuracy?\n",
    "\n",
    "**Answer**: ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "XUSUFlcWqkyq"
   },
   "source": [
    "# Optional: Experimenting with a more complex database\n",
    "\n",
    "We will now move to the fashion MNIST database, in order to experiment with a more complex database. The best test accuracy reported on this database is 0.967 (see https://github.com/zalandoresearch/fashion-mnist).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GdSCSw2Kqkyr",
    "outputId": "0cb2517a-b0bf-4898-eac6-01af32a6a3ee"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist as db\n",
    "\n",
    "# You can use the following dictionary to transform number labels into meaningful labels:\n",
    "fashion_dict = {\n",
    "    0: \"T-shirt/top\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle boot\"\n",
    "    }\n",
    "\n",
    "print(fashion_dict[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and have a look at the data\n",
    "(x, y), (x_test_ori, y_test_ori) = db.load_data()\n",
    "\n",
    "# Visualize a single digit, with its class\n",
    "plt_r,plt_c = 4,4\n",
    "f, ax = plt.subplots(plt_r, plt_c, figsize=(16,16))\n",
    "for i in range(plt_r):\n",
    "    for j in range(plt_c):\n",
    "        index = np.random.randint(x.shape[0])\n",
    "        ax[i][j].imshow(x[index], cmap='gray')\n",
    "        ax[i][j].axis('off')\n",
    "        ax[i][j].set_title(\"Example: {}, Class: {}\".format(index, y[index]))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "_PSbIvpm-91s"
   },
   "source": [
    "Build your own model below, train it on the fashion MNIST database and analyse its results. Dont forget to normalize and put the data into the correct format. Try to reach the highest validation accuracy. Finally, evaluate it using the test database.\n",
    "\n",
    "You must respect the following constraints:\n",
    "\n",
    "* you can use dense, convolutional, and pooling layers in your network;\n",
    "\n",
    "* do not change the optimizer, the loss or the metrics used during training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MMKAc-dd_e1g"
   },
   "outputs": [],
   "source": [
    "# Your code comes here. You can use several cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "K0CKtpx_qkyZ",
    "outputId": "e88062a0-1202-44a2-abd4-77b42c1c8d97"
   },
   "outputs": [],
   "source": [
    "plt.plot(output.epoch, output.history['loss'], label='train')\n",
    "plt.plot(output.epoch, output.history['val_loss'], label='val')\n",
    "plt.title('Training and validation performance')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.grid\n",
    "plt.show()\n",
    "# plt.ylim(0.2, 0.8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "X9WYN_xCjnD2"
   },
   "source": [
    "# Your results on the fashion MNIST database\n",
    "\n",
    "Which pairs of classes are the main cause of confusion?\n",
    "\n",
    "**Answer**: ...\n",
    "\n",
    "\n",
    "Did you use an architecture different than the one used for MNIST? If so, how?\n",
    "\n",
    "**Answer**: ...\n",
    "\n",
    "\n",
    "Is there overfitting?\n",
    "\n",
    "**Answer**: ...\n",
    "\n",
    "**Test accuracy**: ..."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mnist_mlp.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('keras-gpu-py37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "1cd8fa715f4e783bb81f945723edfe74554df81b9cdc3abfedca690bf5dda2c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
